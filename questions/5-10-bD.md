1、transformer 结构，self-attention 实现方式（公式描述），multiHead-attention 怎么做的，最后怎么拼接在一起；
   batch_normalize 和 linear_normalize 的区别？  
   答案要点：公式见论文；$\sqrt{d_{k}}$  
2、softmax 的损失函数？交叉信息熵公式？  
3、LSTM 的结构？用了什么激活函数？为什么能防止梯度爆炸？  
4、胶囊网络 激活函数（公式描述）？  
5、CNN，一个n\*n的输入，过完一个k\*k卷积核，步长为s填充为p，然后过了一个m\*m的池化，输出维度是多少  
6、怎么解决过拟合？ L1 L2 范数有什么区别怎么用？

编程题：快速排序，我写了个归并排序，问时间复杂度，问属于有序排序还是无续排序，最后不知道怎么说问了别的